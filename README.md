# ğŸ§¹ Market Data Cleaning & Validation

## ğŸ“˜ Overview

This project delivers a Python-based solution for ingesting, cleaning, and validating market data from a vendor.  
It was implemented with an emphasis on:

- Transparency of logic and design decisions
- Traceable, testable data cleaning
- Practical performance and extensibility

A core class `MarketDataCleaner` wraps all functionality, keeping the solution modular, readable, and adaptable.

---

## ğŸ“Œ Assumptions & Design Philosophy

Clear, reasoned assumptions underpin this solution:

- âœ… **Only active instruments** from the reference file (`Status == "Active"`) are valid.
- âœ… **Price fields** (`OpenPrice`, `ClosePrice`, `HighPrice`, `LowPrice`) are required and must be numeric.
- âœ… **Volume** and **OpenInterest** are optional but cleaned if present.
- âœ… **Dates** are in `YYYY-MM-DD` format and parsed to `datetime`; invalid dates cause the row to be dropped.
- âœ… Instrument validation relies on exact matches of `Symbol`, `InstrumentType`, and `Exchange`.
- âœ… Extra fields in the reference file (e.g., `Sector`, `ContractMonth`) are ignored unless explicitly used.
- âœ… Symbols formatted like `AAPL.NYSE` will be split into `Symbol=AAPL`, `Exchange=NYSE` when `fix_dot_in_symbol=True` is enabled.


This ensures both **data quality** and **alignment with business rules** without overcomplicating the pipeline.

---

## ğŸ§  Technology Choices

### Why Object-Oriented Design?

Requested by the trader and purpose-built for clarity:

- Keeps logic encapsulated in a `MarketDataCleaner` class
- Enables easy reuse and future extension
- Supports parameterized configuration (e.g., validation flags)
- Encourages structured testing and debugging

### Why Pandas?

- âœ… Fast enough for datasets under ~10M rows
- âœ… Rich, expressive API for data manipulation
- âœ… Familiar to analysts and engineers alike
- âœ… Ecosystem integration (NumPy, datetime parsing, etc.)

While scalable options like Polars or Dask were considered, **Pandas was ideal** for the given file size (~1M rows) and requirements.

---

## ğŸ› ï¸ How the Cleaner Works

1. **Load data** from two CSVs: market and reference
2. **Clean market data**:
   - Strip whitespace from ID fields
   - Convert prices, volume, and open interest to numeric
   - Parse and validate dates
   - Drop rows with missing price/date values
   - Remove duplicates and empty rows
3. **Validate against reference data**:
   - Filter for active instruments
   - Inner join on key fields
   - Drop rows with unmatched or invalid instruments
4. **Log all drops** (if `track_dropped_rows=True`)
5. **Expose results** via `.get_clean_data()` and `.summary()`

---

## ğŸ§ª Testing & Coverage

Unit tests are written using `pytest` and stored in `tests/test_cleaner.py`.

They cover:
- âœ… Successful retention of clean rows
- âœ… Drop logic for malformed rows
- âœ… Duplicate and whitespace cleanup
- âœ… Exception handling when using the class improperly
- âœ… Missing required columns

To run:
```bash
PYTHONPATH=src pytest -v
```

---

## ğŸ§© Edge Case Handling

- âœ… Missing/invalid price or date fields
- âœ… Extra/empty/malformed rows
- âœ… Whitespace and duplicates
- âœ… Reference mismatches
- âœ… Fully empty rows
- âš ï¸ CSV injection (e.g., `=CMD(...)`) not yet handled

---

## ğŸ“Š Evaluation & Future Work

### âœ… Efficiency
- Uses vectorized operations and batch parsing
- Fast for in-memory datasets up to ~10M rows

### ğŸ”§ Improvements Suggested
- Export to CSV/Parquet with formula-safe escaping
- Redact sensitive info in logs
- Add ability to replace missing Exchange field based on reference data (if uniquely identifiable by Symbol + InstrumentType)
- Add CLI or stream processing support
- Track detailed rejection stats (percent dropped, etc.)

---

## ğŸ“ Files

- `main.txt` â€“ Entry point for execution
- `src/cleaner/cleaner.py` â€“ Main logic
- `src/cleaner/logger_config.py` â€“ Logging setup
- `tests/test_cleaner.py` â€“ Full test suite
- `requirements.txt` â€“ Dependencies
- `data/*.csv` â€“ Sample input files

---

## ğŸš€ How to Run

1. Python 3.12+ required  
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Run:
   ```bash
   python main.txt
   ```

---

## ğŸ Conclusion

This solution represents a robust, extensible, and well-documented approach to financial data ingestion.  
Key strengths include:

- Transparent logic with clear assumptions
- Structured logging for auditing
- Full test coverage with meaningful assertions
- OOP architecture aligned with the problem's intent
- Scalable path for future productionization

---

**Author:** Alex Eygenson